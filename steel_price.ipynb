{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import requests\n",
    "import xlrd,xlwt\n",
    "from xlutils.copy import copy\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\玖隆\\物贸公司\\报表\\钢厂价格对比表.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 设置常量\n",
    "PATH = os.path.abspath(r\"D:\\玖隆\\物贸公司\\报表\")\n",
    "FILENAME = \"钢厂价格对比表.xlsx\"\n",
    "SHEETNAME = \"url_map\"\n",
    "OUTCOME_FILE = \"钢厂价格对比表_每日抓取数据.xlsx\"\n",
    "\n",
    "BASE_FILE = os.path.join(PATH,FILENAME)\n",
    "print(BASE_FILE)\n",
    "\n",
    "NEED_NUM = 18  # 需要的记录数\n",
    "\n",
    "CHROME_DRIVER = 'D:\\Python\\驱动\\chromedriver_win32\\chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 0 \n",
    "ncols = 0 \n",
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_para_xlsx(path=PATH, filename=FILENAME, sheetname=SHEETNAME):\n",
    "    # 打开Excel对应的参数需求表\n",
    "    data = xlrd.open_workbook(os.path.join(path,filename))\n",
    "    table = data.sheet_by_name(sheetname)  # 返回一个xlrd.sheet.Sheet()对象\n",
    "    data.sheet_loaded(sheetname)  # 检查某个sheet是否导入完毕\n",
    "    \n",
    "    nrows = table.nrows  #获取该sheet中的有效行数\n",
    "    ncols = table.ncols  # 有效列数\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = open_para_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将参数数据加载进内存\n",
    "para_dic = {}\n",
    "\n",
    "for i in range(NEED_NUM):\n",
    "    para_dic[int(table.cell_value(i+2,5))] = {\"品名\":table.cell_value(i+2,7),\n",
    "                                         \"二级入口网址\":table.cell_value(i+2,1),\n",
    "                                         \"二级入口网址查找对应表名\":table.cell_value(i+2,4),\n",
    "                                         \"每日数据明细条数\":table.cell_value(i+2,6),\n",
    "                                         \"型号\":table.cell_value(i+2,8),\n",
    "                                         \"规格\":table.cell_value(i+2,9),\n",
    "                                         \"钢厂\":table.cell_value(i+2,10),\n",
    "                                         \"CTR值\":table.cell_value(i+2,11),\n",
    "                                         \"匹配原始数据值\":None,\n",
    "                                         \"是否找到对应表名\":False,\n",
    "                                         \"更新成功\":False\n",
    "                                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specfic_table_link(table_content,match_title):\n",
    "    match_a = table_content.findAll(\"a\",title=match_title)  # 在获取到的页面的bs4对象上，继续找到对应a标签对象\n",
    "    \n",
    "    next_a_href_suffix = table_content.findAll(\"a\",title=match_title)[0].get(\"href\")\n",
    "    if next_a_href_suffix.startswith(\"http\"):\n",
    "        next_a_href = next_a_href_suffix\n",
    "    else:\n",
    "        next_a_href = \"https:\" + next_a_href_suffix\n",
    "    return next_a_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_content_href(index,para_dic=para_dic):\n",
    "    url = para_dic.get(index).get(\"二级入口网址\")\n",
    "    match_title = para_dic.get(index).get(\"二级入口网址查找对应表名\")\n",
    "    response = requests.get(url)\n",
    "    html_doc = response.text \n",
    "    soup = BeautifulSoup(html_doc,\"html.parser\")\n",
    "    table_content = soup.find(\"ul\",class_=\"nlist\")\n",
    "    \n",
    "    # 判断是否在第一页就能找到对应的 表名 a标签\n",
    "    titles = table_content.get_text().replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "    \n",
    "    if titles.find(match_title) == -1:\n",
    "        # 找第二页\n",
    "        find_index = soup.find(\"div\",class_=\"page\")\n",
    "        page2 = find_index.find(\"a\")\n",
    "        if page2.contents[0] == \"2\":\n",
    "            page2_change = find_index.find(\"a\")[\"href\"].split(\"-\")[-1]\n",
    "            page2_url = url.replace(\"1.html\",page2_change)\n",
    "            response2 = requests.get(page2_url)\n",
    "            soup2 = BeautifulSoup(response2.text,\"html.parser\")\n",
    "            table_content2 = soup2.find(\"ul\",class_=\"nlist\")\n",
    "            titles2 = table_content2.get_text().replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            if titles2.find(match_title) == -1:\n",
    "                print(\"今日数据尚未更新\")\n",
    "                return para_dic\n",
    "            else: \n",
    "                para_dic[index][\"是否找到对应表名\"] = True\n",
    "                para_dic[index][\"每日新增数据的网址\"] = get_specfic_table_link(table_content2,match_title)\n",
    "    else:\n",
    "        # 如果找到了指定的表名\n",
    "        # 则解析获取对应的a标签的href网址\n",
    "        # 返回对应的表名的 href 字符串\n",
    "        para_dic[index][\"是否找到对应表名\"] = True\n",
    "        para_dic[index][\"每日新增数据的网址\"] = get_specfic_table_link(table_content,match_title) \n",
    "        return para_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取对应的新增网址，所有网址信息都输出，则说明今天数据都更新了\n",
    "for i in range(1,19):\n",
    "    try:\n",
    "        if i != 16:\n",
    "            find_content_href(i)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 True https://jiancai.mysteel.com/m/20/0601/09/BECB369348D80BE0.html\n",
      "2 True https://jiancai.mysteel.com/m/20/0601/12/879A04F465FB5C25.html\n",
      "3 True https://jiancai.mysteel.com/m/20/0601/10/AA6E267349F88E80.html\n",
      "4 True http://youhanxian.mysteel.com/m/20/0601/11/7525E5D00609C38D.html\n",
      "5 True http://youhanxian.mysteel.com/m/20/0601/10/65D0C8B3F5FE29CD.html\n",
      "6 True http://youhanxian.mysteel.com/m/20/0601/10/1083DCECC3AD6591.html\n",
      "7 True http://lengdun.mysteel.com/m/20/0601/10/3ADA9968198EEBD0.html\n",
      "8 True http://lengdun.mysteel.com/m/20/0601/10/E51850D879909B25.html\n",
      "9 True http://lengdun.mysteel.com/m/20/0601/11/3D3D5FCFE56594E6.html\n",
      "10 True https://rezha.mysteel.com/m/20/0601/09/1EB23D45E8238AD3.html\n",
      "11 True https://rezha.mysteel.com/m/20/0601/10/530926BDC2B272AD.html\n",
      "12 True https://rezha.mysteel.com/m/20/0601/10/7890156DCEC43B1B.html\n",
      "13 True https://zhongban.mysteel.com/m/20/0601/10/D7A38FD73FBC3C9A.html\n",
      "14 True https://zhongban.mysteel.com/m/20/0601/10/1B8E807D31A1DC5D.html\n",
      "15 True https://zhongban.mysteel.com/m/20/0601/09/7729D80B69EF4054.html\n",
      "16 False None\n",
      "17 True https://lengzha.mysteel.com/m/20/0601/10/D8FB2DB2916A617A.html\n",
      "18 True https://lengzha.mysteel.com/m/20/0601/10/B045084217312ECA.html\n"
     ]
    }
   ],
   "source": [
    "for k,v in para_dic.items():\n",
    "    \n",
    "    localtime = time.localtime(time.time())\n",
    "    if v.get(\"每日新增数据的网址\") is not None:\n",
    "        extract_month = int(v.get(\"每日新增数据的网址\").split(\"/\")[5][:2])\n",
    "        \n",
    "        if extract_month == localtime.tm_mon:\n",
    "            print(k,v.get(\"是否找到对应表名\"),v.get(\"每日新增数据的网址\"))\n",
    "        else: \n",
    "            para_dic.get(k)[\"是否找到对应表名\"] = False\n",
    "            para_dic.get(k)[\"每日新增数据的网址\"] = None\n",
    "            print(k,v.get(\"是否找到对应表名\"),v.get(\"每日新增数据的网址\"),\"不是当月网址\")\n",
    "    else:\n",
    "        print(k,v.get(\"是否找到对应表名\"),v.get(\"每日新增数据的网址\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最关键的价格数据是ajax返回的，通过selenium模拟服务器，获取ajax数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#指定chrome的驱动\n",
    "#执行到这里的时候Selenium会到指定的路径将chrome driver程序运行起来\n",
    "driver = webdriver.Chrome(CHROME_DRIVER)\n",
    "if para_dic.get(1).get(\"每日新增数据的网址\") is not None:\n",
    "    driver.get(para_dic.get(1).get(\"每日新增数据的网址\"))\n",
    "else:\n",
    "    driver.get(\"https://jiancai.mysteel.com/m/20/0527/09/9C38A68E4E18B9D3.html\")\n",
    "    \n",
    "time.sleep(10)\n",
    "for k,v in para_dic.items():\n",
    "    #get 方法 打开指定网址\n",
    "    if k != 16:\n",
    "        if para_dic.get(k).get(\"每日新增数据的网址\") is not None:\n",
    "            driver.get(para_dic.get(k).get(\"每日新增数据的网址\"))\n",
    "            id_ctr_value = para_dic.get(k).get(\"CTR值\")\n",
    "            #选择网页元素\n",
    "            element_keyword = driver.find_element_by_id(id_ctr_value)\n",
    "            para_dic[k][\"匹配原始数据值\"]=element_keyword.text\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 螺纹钢 Φ16-25 HRB400 沙钢 3670 +20 Ф16:3700;Ф25:3720 代理\n",
      "2 螺纹钢 Ф16 HRB400 韶钢 4040 +40 现货\n",
      "3 螺纹钢 Ф16 HRB400E 河钢承钢 3730 +40 现货\n",
      "4 硬线 45# 热轧 Φ6.5 沙钢 3820 +50 现货\n",
      "5 硬线 45#-70# 热轧 Φ6.5-20 中天钢铁 3860 +30 现货\n",
      "6 硬线 45# 热轧 Φ6.5 潍坊特钢 3710 +30 现货\n",
      "7 冷镦钢 ML08AL 热轧 Φ16-24 沙钢 3910 +60 代理\n",
      "8 冷镦钢 ML08AL 热轧 Φ6.5 中天钢铁 3880 +30 货少 现货\n",
      "9 冷镦钢 ML08AL 热轧 Φ6.5-20 鞍钢 3890 +30 现货\n",
      "10 热轧板卷 5.75*1500*C Q235B 沙钢 3650 +60 货少 现货\n",
      "11 热轧板卷 5.5-11.5*1500*C Q235B 承钢 3700 +60 现货\n",
      "12 热轧板卷 5.75*1500*C Q235B 河钢承钢 3700 +50 现货\n",
      "13 普中板 12 Q235B 沙钢 3950 +40 现货\n",
      "14 普中板 14-20 Q235B 鞍钢 3910 - 代理\n",
      "15 普中板 14-20 Q235B 萍钢 3800 +40 现货\n",
      "16 None\n",
      "17 冷轧卷 1.0*1250*C DC01 本钢 3990 +50 现货\n",
      "18 冷轧卷 1.0*1250*C SPCC 马钢 4080 +30 现货\n"
     ]
    }
   ],
   "source": [
    "for k,v in para_dic.items():\n",
    "    print(k,v.get(\"匹配原始数据值\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将结果写入到excel文件中\n",
    "由于不知道mysteel网站数据会不会发生较大的变化，写的太全面，后期不容易发现和修改，索性只要负责取数据。   \n",
    "数据保存和校验全部在excel中完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打开工作表，保持原表的格式\n",
    "rb = xlrd.open_workbook(os.path.join(PATH,OUTCOME_FILE))\n",
    "wb = copy(rb)\n",
    "ws = wb.get_sheet(\"sheet1\")\n",
    "\n",
    "for i in range(1,19):\n",
    "    if i != 16:\n",
    "        ws.write(i-1,0,para_dic.get(i).get(\"是否找到对应表名\"))\n",
    "        ws.write(i-1,1,para_dic.get(i).get(\"匹配原始数据值\"))\n",
    "    \n",
    "wb.save(os.path.join(PATH,OUTCOME_FILE)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于xlrd和xlwt实在是很鸡肋的用法，而对xlsx格式的表格的支持比较差。\n",
    "xlutils也不能支持过多的excel格式，只能写到新表中，手动打开复制"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
